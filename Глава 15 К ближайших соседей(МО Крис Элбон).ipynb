{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глава 15 К ближайших соседей(МО Крис Элбон)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификатор к ближайших соседей (KNN) является одним из самых простых и наиболеее часто используемых классификатром в контролирум машинном самообучении. KNN часто считается ленивым учеником, он технически не тренерует модель делать предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо этого предсказывается, что наблюдение будет классом наибольшей доли к ближайших наблюдений. Например, если наблюдение с неизвестным классом окружено наблюдением с классом 1, то это наблюдение классифицируется как класс 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отыскание ближайших соседей наблюдения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется найти к-ближайших наблюдений (соседей) некоторого наблюдения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать класс NearestNeighbors библиотеки scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать стандартизатор\n",
    "standardizer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стандартизировать признаки\n",
    "features_standardized = standardizer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#два ближайших соседа\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors=2).fit(features_standardizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать наблюдение\n",
    "new_observation = [1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#найтейи расстояния и индексы ближайших соседей наблюдения\n",
    "distance, indices = nearest_neighbors.kneighbors([new_observation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.03800476, 0.55861082, 1.10378283, 1.18556721],\n",
       "        [0.79566902, 0.32841405, 0.76275827, 1.05393502]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#взглянуть на ближайших соседей\n",
    "features_standardized[indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем решении мы использовали набор данных цветков ириса. Мы создали наблюдение - new_observation, с некоторыми значениями, а затем нашли 2 наблюдения, которые ближе всего к нашему наблюдению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переменная indices содержит наиболее близкие местоположения наблюдений в нашем наборе данных, и X[indices] показывает значения этих наблюдений. Интуитивно расстояние можно рассматривать, как меру сходства, поэтому два ближайших наблюдения - это два цветка, наиболее похожих на цветок, который мы создади."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как измерять растояние? Библиотека scikit-learn предлагает широкий выбор метрических показателей расстояния d, включая евклидово расстояние:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} d_{евклидово} = \\sqrt{{\\sum_{i=1}^{n} (x_i-y_i)^2} } \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и матхэттенское расстояние:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} d_{манхэттенское} = \\sqrt{{\\sum_{i=1}^{n} |x_i-y_i|} } \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию класс NearestNeighbors использует расстояние Минковского:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} d_{минковского} = ({{\\sum_{i=1}^{n} |x_i-y_i|^p}} ) ^ {1/p} \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где x_i и  y_i - два наблюдения, между которыми мы вычисляем расстояние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расстояние Минковского включает гиперпараметр p, где p=1 это матхэтонское расстояние, p=2 евклидово расстояние. В библиотеке scikit-learn  по умолчанию p=2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрический  показатель расстояния можно установить с помощью параметра metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#найти двух ближайших соседей на основе евклидова расстояния\n",
    "nearestneighbors_euclidean = NearestNeighbors(n_neighbors=2, metric='euclidean').fit(features_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Созданная нами переменная distance содержит фактическое измерение расстояния до каждого из двух ближайших соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49140089, 0.74294782]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#взглянуть на расстояния\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, для создания матрицы, показывающей ближайших соседей каждого наблюдения, можно использовать метод kneighbors_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#найти трех ближайших соседей каждого наблюдения\n",
    "#на основе евклидового расстояния (включая себя)\n",
    "nearestneighbors_euclidean = NearestNeighbors(n_neighbors=3, metric='euclidean').fit(features_standardized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Список списков, показывающий 3-х ближайших соседей каждого наблюдения(включая себя)\n",
    "nearest_neighbors_with_self = nearestneighbors_euclidean.kneighbors_graph(features_standardized).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors_with_self.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors_with_self[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удалить единицы, отметив наблюдение, как ближайший сосед к себе\n",
    "for i, x, in enumerate(nearest_neighbors_with_self):\n",
    "    x[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#взглянуть на ближайших соседей первого наблюдения\n",
    "nearest_neighbors_with_self[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы находим ближайших соседей или используем любой обучающий алгоритм, основанный на расстоянии, важно преобразовать признаки так, чтобы они были на одной шкале."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Причина в том, что метрики расстояния относятся ко всем признакам, как если бы они были на одной шкале, но если один признак находится в миллионах долларов, а второй - в процентах, то вычисленное расстояние будет смещено в сторону первого. В нашем решении мы решили эту потенциальную проблему путем стандартизации признаков с помощью класса StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание классификационной модели k ближайших соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дано наблюдение неизвестного класса, и требуется предсказать его класс на основе класса его соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если набор данных не очень большой, то использовать класс KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать стандартизатор\n",
    "standardizer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стандартизировать признаки\n",
    "X_std = standardizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать классификатор KNN с пятью соседями\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1).fit(X_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать два наблюдения\n",
    "new_observation = [[0.75, 0.75, 0.75, 0.75],\n",
    "                  [1, 1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать класс двух наблюдений\n",
    "knn.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В KNN, если дано наблюдение x_u с неизвестным целевым классом, то алгоритм сначала идентефицирует к-ближайших наблюдений (иногда называемых окрестностью x_u) на основе некоторого метрического показателя расстояния (например, евклидова расстояния), затем эти к-наблюдений \"голосуют\" на основе их класса, и класс, который побеждает в голосовании, является предсказанным классом для x_u.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более формально вероятность x_u некоторого класса j имеет вид:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} 1/k {\\sum_{i ∈ v} I(y_i=j)}  \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где v - k-е наблюдение в окресности x_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_i - класс i-го наблюдения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I - индикаторная функция ( т е 1- истинно, 0 -в противном случае)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке scikit-learn эти вероятности можно увидеть с помощью метода predict_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.6, 0.4],\n",
       "       [0. , 0. , 1. ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#взглянуть на вероятность, что каждое наблюдение является одним из трех классов\n",
    "knn.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс с наибольшей вероятностью становится предсказанным классом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, в приведенных выше результатах первое наблюдение должно быть классом 1 (Pr=0.6), в то время как второе наблюдение должно быть классом 2(Pr=1), и это именно то, что мы видим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке  scikit-learn класс KNeighborsClassifier содержит ряд важных параметров, которые следует рассмотреть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр metric задает используемый метрический показатель расстояния."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр n_jobs определяет, сколько ядер компьютера использовать. Рекомендуется использовать несколько ядер, поскольку, предсказание требует вычисления расстояния от некоторой точки, до каждой отдельной точки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр algorithm задает метод расчета ближайших соседей. хотя существуют реальные различия в алгоритмах, по умолчанию класс KNeighborsClassifier пытается автоматически вабрать наилучший алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификатор KNeighborsClassifier работает как описано ранее, при этом каждое наблюдение в окресности получает один голос, однако если мы зададим параметр веса weights равным значению distance, то голоса более близких наблюдений, будут весить больше, чем наблюдения расположенные дальше.\n",
    "\n",
    "Интуитивно это имеет смысл, поскольку более похожие соседи могут рассказать нам больше о классе наблюдения, чем другие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно перед использованием классификатора KNN стандартизировать признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Идентификация наилучшего размера окрестности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется выбрать наилучшее значение для k в классификационной модели k-ближайших соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать методы отбора модели, такие как поиск в решетке параметров, реализованный в классе GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать стандартизатор\n",
    "standardizer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стандартизировать признаки\n",
    "features_standardized = standardizer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать классификатор knn\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать конвейер\n",
    "pipe = Pipeline([(\"standardizer\", standardizer),(\"knn\", knn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать пространство вариантов значений\n",
    "search_space = [{\"knn__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект решеточного поиска\n",
    "classifier = GridSearchCV(pipe, search_space, cv=5, verbose=0).fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В классификаторах KNN размер к имеет реальные последствия. В машинном самообучении мы пытаемся найти баланс между смещением и дисперсией, и не так уж много мест, где это проявляется также явно, как в значении к. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если к=n, где n - число наблюдений, то мы имеем высокое смещение, но низкую дисперсию. Если к=1, то мы будем иметь низкое смещение, но высокую дисперсию.\n",
    "\n",
    "Лучшая модель будет получена из нахождения значения к, которое уравновешивает это компромисное соотношение смещение-дисперсии. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем решении мы использовали объект класса GridSearchCV для проведения пятиблочной перекрестной проверки на классификаторах KNN с различными значениями k. Когда она будет завершена, мы увидим k, которое производит наилучшую модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D0%BB%D0%B5%D0%BC%D0%BC%D0%B0_%D1%81%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D1%8F%E2%80%93%D0%B4%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D0%B8%D0%B8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наилучший размер окрестности к\n",
    "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание радиусного классификатора ближайших соседий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дано наблюдение неизвестного класса, и требуется предсказать его класc на основе класса всех наблюдений в пределах определенного расстояния."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать класс RadiusNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать стандартизатор\n",
    "standardizer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стандартизировать признаки\n",
    "features_standardized = standardizer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать радиусный классификатор соседей\n",
    "rnn = RadiusNeighborsClassifier(radius=.5, n_jobs=-1).fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать наблюдение\n",
    "new_observation = [[1, 1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать класс наблюдения\n",
    "rnn.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В классификации KNN класс наблюдений предсказывается из классов его к соседий.\n",
    "\n",
    "Менее распространенным методом является классификация в радиусном классификаторе (RNN), где класс наблюдения предсказывается из классов всех наблюдений в пределах в пределах заданного радиуса r. В библиотеке skikit-learn радиусный классификатор RadiusNeighborsClassifier очень похож на классификатор к ближайших соседей KNeighborsClassifier, за исключением 2-х параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В радиусном классификаторе RadiusNeighborsClassifier нужно с помощью параметра radius указать радиус фиксированной области, используемой для определения, является ли наблюдение соседом.\n",
    "\n",
    "Если нет какой-либо существенной причины, для установки параметра radius в некоторое значение, лучше рассматривать его как любой другой гиперпараметр и настраивать его во время отбора модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй полезный параметр - outlier_label, указывающий на то, какую метку дать наблюдению, которое не имеет наблюдений в заданном радиусе, что само по себе часто может быть полезным инструментом для идентификации выбросов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
