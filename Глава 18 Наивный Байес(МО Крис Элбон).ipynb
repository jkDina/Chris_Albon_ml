{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глава 18 Наивный Байес(МО Крис Элбон)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теорема Байеса является главным методом для понимания вероятности  некоторого события P(A|B) при наличии некой новой информации, P(B|A) и априорной субъективной оценки вероятности события P(A):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} P(A|B) =  \\frac{P(B|A)P(A)} {P(B)}  \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В машинном самообучении одно из применений теоремы Байеса к классификации проявляется в виде наивного байесового классификатора. \n",
    "\n",
    "Наивные байесовые классификаторы объединяют в общий классификатор ряд желательных в практическом машинном самообучении качеств:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-интуитивно понятный подход\n",
    "\n",
    "-возможность работы с малыми данными\n",
    "\n",
    "-низкие затраты на тренировку и предсказание\n",
    "\n",
    "-часто надежные результаты в разнообразных условиях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В частности, наивный байесов классификатор основан на следующей формуле:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} P(y|x_1,...x_j) =  \\frac{P(x_1,...x_j|y)P(y)} {P(x_1,...x_j)}  \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(y|x_1,...x_j) - апостериорное значение, является вероятностью  того, что наблюдение принадлежит классу y при условии, что это наблюдение имеет значения j признаков x_1,...x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(x_1,...x_j|y) - называется правдоподобием и является правдоподобной оценкой вероятности, что наблюдение имеет значения признаков x_1,...x_j, при условии, что дан их класс y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(y) - называется априорной вероятностью и является нашей субъективной оценкой вероятности класса перед рассмотрением данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(x_1,...x_j) - называется предельной вероятностью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В наивном Байерсе мы сравниваем апостериорные значения наблюдения для каждого возможного класса. В частности, поскольку во всех сравнениях предельная вероятность постоянна, мы сравниваем числители апостериорного значения для каждого класса. \n",
    "\n",
    "Для каждого наблюдения класс с наибольшим апостериорным числителем становится предсказанным классом y\\hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отношении наивных байесовых классификаторов следует отметить 2 важных момента.\n",
    "\n",
    "1)Для каждого признака в данных мы должны принять статистическое распределение правдоподобно оцененных вероятностей  P(x_j|y).\n",
    "\n",
    "Общепринятыми распределениями являются нормалное(гауссово), полиноминальное и бернулево распределения.\n",
    "\n",
    "Выбор распределения нередко определяется природой признаков(непрерывных, бинарных).\n",
    "\n",
    "2)Название наивный Байес обусловлено тем, что мы допускаем независимость каждого признака и результирующей правдоподобной оценки его вероятности.\n",
    "\n",
    "Это \"наивное\" допущение часто неверно , но на практике мало чем мешает созданию высококачественных классификаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой главе рассмотрим использование библиотеки scikit-learn для тренировки 3-х типов наивных байесовых классификаторов с использованием 3-х различных распределений правдоподобно оцениваемых вероятностей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка классификатора для непрерывных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даны только непрерывные признаки, и требуется натренировать наивный байесов классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать гауссов наивный байесов классификатор в библиотеке scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект гауссова наивного Байеса\n",
    "classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = classifier.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее распространенным типом наивного байесова классификатора является гауссов наивный Байес. В гауссовом наивном Байесе мы принимаем допущение, что правдоподобие признаковых значений x при условии, что наблюдение принадлежит классу y, подчиняется нормальному распределению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} P(x_i|y) =  \\frac{1}{\\sqrt {2 \\pi \\sigma_y^2}} exp({\\frac{(x_i - \\mu_y)}{2\\sigma_y^2}) }\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigma_y^2 - дисперсия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mu_y - среднее значение признака x_j для класса y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за принятого допущения о нормальном распределении гауссов наивный Байес лучше всего использовать  в случаях, когда все наши признаки непрерывны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке scikit-learn мы тренируем гауссов наивный Байес, как другую любую модель, используя метод fit, и, в свою очередь, можем делать предсказания о классе наблюдения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать новое наблюдение\n",
    "new_observation = [[4, 4, 4, 0.4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать класс\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из  интересных аспектов наивных байесовых классификаторов заключается в том, что они позволяют назначать априорную субъективную оценку в отношении вероятностей целевых классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это можно сделать с помощью параметра priors класса GaussianNB, этот параметр принимает список вероятностей, присваиваемых каждому классу вектора целей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект гаусова наивного Байеса\n",
    "#с априорными вероятностями для каждого класса\n",
    "clf = GaussianNB(priors=[0.01, 0.01, 0.98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = clf.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать новое наблюдение\n",
    "new_observation = [[4, 4, 4, 0.4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать класс\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы не добавляем никаких аргументов в параметр priors, то априорные оценки настраиваются на основе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, обратите внимание, что сырые предсказанные вероятности из гауссова наивного Байерса (выведенные с помощью метода predict_proba) не калиброванны, т е им не стоит верить. Если требуется создать полезные предсказанные вероятности, нам нужно их откалибровать с помощью изотонической регрессии или родственного метода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.34061855e-38, 9.95097176e-01, 4.90282363e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка классификатора для дискретных и счетных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даны дискретные или счетные данные, требуется натренировать наивный байесов классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать полиноминальный наивный байесов класссификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#зашрузить библиотеки\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать текст\n",
    "text_data = np.array(['Бразилия - моя любовь. Бразилия!', 'Бразилия - лучше', 'Германия бьет обоих'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать мешок слов\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать матрицу признаков\n",
    "features = bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать вектор целей\n",
    "target = np.array([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект полиноминального наивного байесова классификатора\n",
    "#с априорными вероятностями каждого класса\n",
    "classifer = MultinomialNB(class_prior=[0.25, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = classifer.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полиноминальный наивный байес работае аналогично гауссовому наивному Байесу, только здесь признаки подчиняются полиноминальному распределению. На практике это означает, что данный классификатор обычно используется , когда имеются дискретные данные ( например, рейтинги фильмов в диапазоне от 1 до 5).\n",
    "\n",
    "Одним из наиболее распространенных применений полиноминальных наивных байесовых классификаторов является классификация текста с использованием подходов на основе мешков слов  или статистических мер tf-idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем решении мы создали игрушечный набор текстовых данных из трех наблюдений и преобразовали текстовые строки в матрицу признаков и сопутствующий вектор целей по методу мешка слов. Затем мы использовали класс MultinominalNB, для того, чтобы натренировать модель, при этом определив априорные вероятности для двух классов (пробразильский и прогерманский)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс MultinominalNB работает аналогично классу GaussianNB. Модели тренируются с использованием метода fit, а наблюдения можно предсказать с помощью метода predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['бразилия', 'бьет', 'германия', 'лучше', 'любовь', 'моя', 'обоих']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создать новое наблюдение \n",
    "#как будто мы векторизовали новый текст (см ниже)\n",
    "new_observation = [[0, 0, 0, 1, 0, 1, 0]]\n",
    "count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать класс нового наблюдения\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если параметр class_prior не задан, то априорные вероятности заучиваются на основе данных. Однако если мы хотим, чтобы в качестве априорного распределения использовалось равномерное, то можно задать fit_prior=False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец,  классMultinominalNB содержит гиперпараметр аддитивного сглаживания alpha, который должен быть настроен. Принятое значение по умолчанию равняется 1.0, при этом значение 0.0 означает отсутствие сглаживания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data = np.array(['моя лучше'])\n",
    "count.transform(predict_data)\n",
    "count.transform(predict_data).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка наивного байесова классификатора для бинарных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеются двоичные признаковые данные, и требуется натренировать наивный байесов классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать бернуллев наивный байесов классификатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить библиотеки\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать три бинарных признака\n",
    "features = np.random.randint(2, size=(100, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создать вектор бинарных целей\n",
    "target = np.random.randint(2, size=(100, 1)).ravel()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект бернуллиева наивного Байеса \n",
    "#с априорными вероятностями каждого класса\n",
    "classifer = BernoulliNB(class_prior=[0.25, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = classifer.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бернуллиев наивный байесов классификатор принимает допущение, что все наши признаки являются бинарными, т е принимают только два значения (например, номинальный категориальный признак, который был представлен в кодировке с одним активным состоянием).\n",
    "\n",
    "Как и его полиноминальный двоюродный брат, бернуллиев наивный Байес часто используется  в классификации текста, когда наша матрица признаков - это просто \n",
    "присутствие или отсутствии слова в документе.\n",
    "\n",
    "Кроме того, как и класс MultinominalNB, класс BernoulliNB имеет гиперпараметр аддитивного сглаживания alpha, который требуется настроить с помощью методов отбора модели. \n",
    "\n",
    "Наконец, если необходимо использовать  априорные вероятности, то можно применить параметр class_prior со списком, содержащем априорные вероятности для каждого класса. \n",
    "\n",
    "Если требуется указать равномерную априорную вероятность, то можно указать fit_prior=False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uniform_prior = BernoulliNB(class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model_uniform_prior = model_uniform_prior.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uniform_prior.predict([[0, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Калибровка предсказанных вероятностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется откалибровать предсказанные вероятности из наивных байесовых классификаторов, чтобы они были интерпретируемы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать класс CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект гауссова наивного Байеса\n",
    "classifer = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать откалиброванную перекрестную проверку \n",
    "#с сигмоидальной калибровкой\n",
    "classifer_sigmoid = CalibratedClassifierCV(classifer, cv=2, method='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=GaussianNB(priors=None,\n",
       "                                                 var_smoothing=1e-09),\n",
       "                       cv=2, method='sigmoid')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#откалибровать вероятности\n",
    "classifer_sigmoid.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать новое наблюдение\n",
    "new_observation = [[2.6, 2.6, 2.6, 0.4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#взглянуть на откалиброванные вероятности\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31859969, 0.63663466, 0.04476565]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "classifier = GaussianNB()\n",
    "classifier_sigmoid = CalibratedClassifierCV(classifier, cv=2, method=\"sigmoid\")\n",
    "classifier_sigmoid.fit(features, target)\n",
    "new_observation = [[2.6, 2.6, 2.6, 0.4]]\n",
    "classifier_sigmoid.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятности классов являются общепринятой и полезной частью машинно-обучающихся моделей. \n",
    "\n",
    "В библиотеке scikit-learn большинство обучающихся алгоритмов позволяют нам видеть предсказанные вероятности принадлежности классу с помощью метода predict_proba.\n",
    "\n",
    "Это может быть очень полезно, когда, например, требуется предсказать только конкретный класс, если модель предсказывает вероятность того, что класс превышает 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, некоторые модели, включая наивные баесовые классификаторы, выводят вероятности, не основанные на реальном мире."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т е метод predict_proba может предсказать, что наблюдение имеет шанс быть конкретным классом, составляющий 0.7, когда в реальности он равняется 0.10 или 0.99."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В частности, в то время как в наивном Баесе ранжирование предсказанных вероятностей для разных целевых классов соответствует действительности, сырые предсказанные вероятности имеют тенденцию принимать предельные значения, близкие к 0 или 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы получить содержательные предсказанные вероятности, нам нужно провести так называемую калибровку. \n",
    "\n",
    "Для создания хорошо откалиброванных предсказанных вероятностей в библиотеке scikit-learn можно применять класс CalibratedClassifierCV с использованием к-блочной перекрестной проверки.\n",
    "\n",
    "В классе CalibratedClassifierCV тренировочные наборы применяются для тренировки модели, а тестовый набор используется для калибровки предсказанных вероятностей.\n",
    "\n",
    "Возвращаемые предсказанные вероятности представляют собой среднее из к блоков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью нашего решения мы можем увидеть разницу между сырыми и хорошо откалиброванными предсказанными вероятностями.\n",
    "\n",
    "В нашем решении мы создали гауссов наивный баесов классификатор.\n",
    "\n",
    "Если натренировать этот классификатор, а затем предсказать вероятности классов для нового наблюдения, то мы увиди абсолютно предельные оценки вероятностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.31548432e-04, 9.99768128e-01, 3.23532277e-07]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#натренировать гауссов наивный байес и затем предсказать вероятности классов:\n",
    "classifer.fit(features, target).predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако после калибровки предсказанных вероятностей(что мы и сделали в нашем решении) мы получим совсем другие результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31859969, 0.63663466, 0.04476565]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#взглянуть на откалиброванные вероятности\n",
    "classifier_sigmoid.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс CalibratedClassifierCV предлагает 2 метода калибровки: сигмоидную модель Платта и изотоническую регрессию, определяемую параметром method.\n",
    "\n",
    "Поскольку изотоническая регрессия является непараметрической, она имеет тенденцию к переподгонке, когда размеры выборки очень малы (напр. 100 наблюдений).\n",
    "\n",
    "В нашем решении мы использовали набор данных цветков ириса со 150 наблюдениями и поэтому выбрали сигмоидальную модель Платта."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
