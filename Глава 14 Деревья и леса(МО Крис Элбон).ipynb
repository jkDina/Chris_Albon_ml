{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глава 14 Деревья и леса(МО Крис Элбон)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка классификационного дерева принятия решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется натренировать классификатор, используя дерево принятия решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать класс DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект классификатор дерева принятия решений\n",
    "decisiontree = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = decisiontree.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решающие деревья пытаются найти правило принятия решения, которое приводит к наибольшему снижению разнородности в узле. Хотя существует ряд мер разнородности, по умолчанию в классе DecisionTreeClassifier, используется коэффициент разнородности Джинни:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} G(t) = 1 - {\\sum_{i=1}^{c} p_i^2} \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} G(t)  \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- коэффициент разнородности Джинни в узле t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} p_i  \\end{equation*}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- доля наблюдений класса с в узле t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный процесс нахождения правил принятия решений, которые создают расщепления для уменьшения разнородности, повторяется рекурсивно до тех пор, пока все конечные узлы не станут однородными( т е пока не будут соддержать только один класс) или пока не будет достигнута некоторая произвольная точка отсечения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://habr.com/ru/post/171759/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://habr.com/ru/company/ods/blog/350440/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке scikit-learn  объект класса работает, как и другие методы самообучения, после того, как модель натренирована с использованием метода fit, полученную модель можно применять для предсказания класса наблюдения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сконструировать новое наблюдение\n",
    "observation = [[5, 4, 3, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать класс наблюдения\n",
    "model.predict(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#мы также можем увидеть предсказанные вероятности  классов наблюдения\n",
    "#взглянуть на предсказанные вероятности трех классов\n",
    "model.predict_proba(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если требуется использовать другую меру разнородности, мы можем применить параметр criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект-классификатор дерева принятия решений, используя энтропию\n",
    "decisiontree_entropy = DecisionTreeClassifier(criterion='entropy', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model_entropy = decisiontree_entropy.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#сконструировать новое наблюдение\n",
    "observation = [[5, 4, 3, 2]]\n",
    "#предсказать класс наблюдения\n",
    "model_entropy.predict(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_entropy.predict_proba(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка регрессионного дерева принятия решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется натренировать регрессионную модель с помощью дерева принятия решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать класс DecisionTreeRegressor библиотеки scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные только с двумя признаками\n",
    "boston = datasets.load_boston()\n",
    "features = boston.data[:, 0:2]\n",
    "target = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'filename', 'target']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект-классификатор дерева принятия решений\n",
    "decisiontree = DecisionTreeRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = decisiontree.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "регрессионное дерево принятия решений работает аналогично классификационному дереву принятия решений, однако вместо уменьшения коэффициента разнородности Джини или энтропии потенциальные расщепления по умолчанию измеряются по тому, насколько они уменьшают среднюю квадратичную ошибку(MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*} MSE = 1/n  {\\sum_{i=1}^{n}( y_i-\\hat y_i)^2} \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_i истинное значение цели\n",
    "\n",
    "hat y_i предсказанное значение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке sklearn регресия на основе дерева принятия решений может проводиться с помощью класса DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы натренировали дерево принятия решений, его можно использовать для предсказания целевого значения для некого наблюдения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сконструировать новое наблюдение\n",
    "observation = [[0.02, 16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIM per capita crime rate by town\n",
    "\n",
    "# ZN proportion of residential land zoned for lots over 25,000 sq.ft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать значение наблюдения\n",
    "model.predict(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно использовать параметр criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, можно построить дерево, расщепления которого уменьшают среднюю абсолютную ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект-классификатор дерева принятия решений, используя энтропию\n",
    "decisiontree_mae = DecisionTreeRegressor(criterion=\"mae\", random_state=0)\n",
    "model_mae = decisiontree_mae.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация модели дерева принятия решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется визуализировать модель, созданную обучающимся алгоритмом дерева принятия решений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экспортировать модель дерева принятия решений в формат DOT, затем визуализировать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1bb88603c268>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#загрузить библиотеки\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "import pydotplus\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn import datasets\n",
    "from IPython.display import Image\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект-классификатор дерева принятия решений\n",
    "decisiontree = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = decisiontree.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать данные в формате DOT\n",
    "dot_data = tree.export_graphviz(decisiontree,\n",
    "                               out_file=None,\n",
    "                               feature_names=iris.feature_name,\n",
    "                               class_names=iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#начертить граф\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#показать граф\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одно из приемуществ классификационного дерева принятия решений - то, что мы можем визуализировать всю натренированную модель целиком. И это делает деревья решений - одними из самых интерпретируемых моделей в МО."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы экспортировали натренированную модель в формате DOT(на языке описания графов), а затем использовали его для построения графа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на корневой узел: правило принятия решения заключается в том, что если ширина липестка меньше или равна 0.8, то следует перейти к левой ветви, иначе перейти к правой ветви."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем увидеть коэффициент неоднородности Джини(0.667), количество наблюдений(150), количество наблюдений в каждом классе ([50, 50, 50]) и класс в котором наблюдения будут предсказаны, если мы остановимся на этом узле (setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы также видим, что в этом узле ученик обнаружил, что одно правило принятия решения (ширина лепестка petal_width (cm) <=0.8 ) смогло идеально идентифицировать все наблюдения класса setosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, при наличии еще одного правила принятия решений с тем же признаком(ширина лепестка petal_width (cm) <=1.75 ) дерево принятия решений способно правильно классифицировать 144 из 150 наблюдений. Это делает ширину липестка очень важным признаком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы хотм использовать дерево принятия решений в других приложениях или отчетах, мы можем легко экспортировать визуализацию в файл PDF или изображение в формате PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать PDF\n",
    "graph.write_pdf(\"iris.pdf\")\n",
    "#True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать PNG\n",
    "graph.write_png(\"iris.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.write_png(\"iris.png\")\n",
    "from PIL import Image\n",
    "Image.open('iris.png').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это решение визуализировало классификационное дерево принятия решений, его можно легко использовать для визуализации регрессионного дерева принятия решений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка классификационного случайного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется натренировать классификационную модель, используя \"лес\" рандомизированных деревьев принятия решений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Натренировать классификационную модель случайного леса, используя класс RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 112 from C header, got 124 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект-классификатор случайного леса\n",
    "randomforest = RandomForestClassifier(random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#натренировать модель\n",
    "model = randomforest.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема деревьев принятия решений  - они как правило слишком плотно прилегают к тренировочным данным(т е подвержены переподгонке). Этот факт мотивировал широкое использование ансамблевого метода самообучения, называемого случайным лесом. В случайном лесу тренируется множество деревьев принятия решений, но каждое дерево получает только бутстраповскую выборку наблюдений (те случайную выборку наблюдений с возвратом, которая соответствует исходному количеству наблюдений). И каждый узел во время наблюдения наилучшего расщеспления рассмотривает только подмножество признаков. Этот лес рандомизированных деревьев принятия решений принимает участие в голосовании с целью определить предсказанный класс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс RandomForestClassifier работает аналогично DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сконструировать новое наблюдений\n",
    "observation = [[5, 4, 3, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать класс наблюдения\n",
    "model.predict(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс RandomForestClassifier использует многие из тех же параметров, что и  DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, можно изменить используемую меру качества расщепления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать  объект-классификатор случайного леса, используя энтропию\n",
    "randomforest_entropy = RandomForestClassifier(criterion=\"entropy\", random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#натренировать модель\n",
    "model_entropy = randomforest_entropy.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будучи лесом, а не отдельным деревом принятия решений, класс RandomForestClassifier  имеет определенные параметры, которые либо уникальны для случайных лесов, либо особенно важны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_features - определяет максимальное количество признаков, которые будут рассматриваться на каждом узле, и принимает ряд аргументов, включая целые числа(количество признаков), вещественные (процент признаков) и sqrt (квадратный корень из числа признаков).\n",
    "\n",
    "по умолчанию max_features присваивается auto, которое действует так же как и sqrt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bootstrap - позволяет задать будет ли подмножество наблюдений, расматриваемого для дерева, создаваться с использованием выборки с возвратом(настройка по умолчанию) либо без возврата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators - задает количество деревьев решений для включения в лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ранее рассматривали n_estimators как гиперпараметр и визуализировали эффект увеличения числа деревьев на оценочном метрическом показателе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто полезно использовать все доступные ядра n_jobs=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка регрессионного случайного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется натренировать регрессионную модель, используя \"лес\" рандомизированных деревьев принятия решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Идентификация важных признаков в случайных лесах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется узнать, какие признаки наиболее важны в модели случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отбор важных признаков в случайных лесах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка несбалансированных классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Управление размером дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшение результативности с помощью бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценивание случайных лесов с помощью ошибок внепакетных наблюдений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
