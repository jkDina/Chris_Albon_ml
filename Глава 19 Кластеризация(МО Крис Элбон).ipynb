{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глава 19 Кластеризация(МО Крис Элбон)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В большинстве случаев мы рассматривали контролируемое машинное самообучение - задачи, в которых имеется доступ как к признакам, так и к цели. Это к сожалению не всегда так. Часто мы сталкиваемся с ситуациями, когда нам известны только признаки. Например, представьте, что заданы записи  о продажах из продуктового магазина, и требуется разбить продажи по признаку, является ли покупател членом дисконтного клуба  или нет.\n",
    "\n",
    "Это было бы невозможно при использовании контролируемого самообучения, потому, что у нас нет цели  для проведения тренировки и оценивания наших моделей.\n",
    "\n",
    "Однако есть идругой вариант: неконтролируемое самообучение. Если поведение членов и нечленов дисконтного клуба в продуктовом магазине фактически разрозненное, то разница в поведении между двумя членами будет меньше, чем разница в поведении между покупателями-членами и нечленами.\n",
    "Иными словами, будут две группы наблюдений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель кластеризующих алгоритмов состоит в том, чтобы идентифицировать эти скрытые группы наблюдений, которые при приемлемом исполнении позволят предсказывать класс наблюдений даже без вектора целей. \n",
    "\n",
    "Существует множество кластеризующих алгоритмов, и они имеют широкий спектр подходов к идентификации кластеров в данных. В этой главе мы рассмотрим подборку класстеризующих алгоритмов с использованием библиотеки scikit-learn и то, как их применять на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация с помощью k - средних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется сгруппировать наблюдения в k - групп."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать кластеризацию методом k средних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стандартизировать признаки\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект k средних\n",
    "cluster = KMeans(n_clusters=3, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = cluster.fit(features_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация методом k - является одним из наиболее распространенных методов кластеризации. В этом методе алгоритм пытается сгруппировать наблюдения в k групп, причем каждая группа имеет примерно равную дисперсию. Количество групп k задается пользователем в качестве гиперпараметра. В частности в алгоритме k средних:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.В случайных позициях создается k \"центральных\" точек, по одной на кластер.\n",
    "\n",
    "2.Для каждого наблюдения:\n",
    "\n",
    "-вычисляется растояние между каждым наблюдением и k центральными точками;\n",
    "\n",
    "-наблюдение назначается кластеру ближайшей центральной точки.\n",
    "\n",
    "3.Центральные точки передвигаются в средние значения (те в центры) своих соответствующих кластеров.\n",
    "\n",
    "4.Шаги 2 и 3 повторяются до тех пор, пока ни одно из наблюдений не изменит свою принадлежность к кластеру.\n",
    "\n",
    "На этом этапе алгоритм считается достигшим схождения и останавливается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Относительно алгоритма k средних важно отметить 3 момента.\n",
    "\n",
    "1)Кластеризация методом k средних исходит из того, что кластеры имеют выпуклую форму (например, форму круга или сферы).\n",
    "\n",
    "2)Все признаки шкалированы одинаково. В нашем решении для того, чтобы соблюсти это допущение, мы стандартизировали признаки.\n",
    "\n",
    "3)Группы сбалансированы, т е имеют примерно одинаковое количество наблюдений. \n",
    "Если мы подозреваем, что не сможем выполнить эти допущения, мы можем попробовать другие подходы к кластеризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке scikit-learn кластеризация методом k средних реализована в классе KMeans. Наиболее важным параметром является n_clusters, который задает количество кластеров k.\n",
    "\n",
    "В некоторых ситуациях характер данных будет определять значение k (например, данные об учениках школы будут иметь один кластер на класс), но зачастую количество кластеров мы не знаем.\n",
    "\n",
    "В этих случая требуется выбрать k на основе некоторых критериев.\n",
    "\n",
    "Например, силуэтные коэффициенты измеряют подобие внутри кластеров по сравнению с подобием между кластерами.\n",
    "\n",
    "Кроме того, поскольку кластеризация методом k средних является вчислительно дорогостоящей, можно воспользоваться всеми ядрами на нашем компьютере. \n",
    "Мы можем сделать это установив параметр n_jobs=-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем решении мы пошли на небольшой обман иДля  воспользовались данными цветков ириса, о которых мы знаем, что они имеют 3 класса.\n",
    "Поэтому мы устанавливаем k = 3. Для просмотра предсказанных классов каждого наблюдения  можно использовать атрибут labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#взглянуть на предсказанный класс\n",
    "model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы сравним этот результат с истинным классом наблюдений, то увидим, что, несмотря на разницу в метках классов( т е 1, 2, 3), алгоритм k средних справился с работой достаточно хорошо. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#взглянуть на истинный класс\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, как Вы можете себе представить производительность алгоритма k средних значительно падает, и даже критически, если мы выберем неправильное количество кластеров.\n",
    "\n",
    "Наконец, как и в случае с другими результатами библиотеки scikit-learn, мы можем использовать натренированный кластер для предсказания значения новых наблюдений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать новое наблюдение\n",
    "new_observation = [[0.8, 0.8, 0.8, 0.8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать кластер наблюдения\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно предсказаниям, наблюдение принадлежит тому кластеру, центральная точка которого находится ближе всего. Для того, чтобы увидеть эти центральные точки, мы даже можем воспользоваться атрибутом cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.13597027,  0.08842168,  0.99615451,  1.01752612],\n",
       "       [-1.01457897,  0.85326268, -1.30498732, -1.25489349],\n",
       "       [-0.05021989, -0.88337647,  0.34773781,  0.2815273 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#взглянуть на центры кластеров\n",
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ускорение кластеризации методом k - средних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется сгрупировать наблюдения  в k групп, но алгоритм k средних занимает слишком много времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать мини-пакетный алгоритм k средних:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стандартизировать признаки\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект k средних\n",
    "cluster = MiniBatchKMeans(n_clusters=3, random_state=0, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = cluster.fit(features_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мини-пакетный алгоритм k средниих работает аналогично алгоритму k средних, описанному в предыдущем рецепте. Не вдаваясь в подробности, разница состоит в том, что в мини-пакетном алгоритме к средних наиболее вычислительно затратный шаг выполняется только на случайной выборке наблюдений в отличии от всех наблюдений, используемых в обычном алгоритме.\n",
    "\n",
    "Такой подход позволяет значительно сократить время, необходимое алгоритму для нахождения сходимости ( т е подгонки данных) при небольшой стоимости в качестве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс MiniBatchKMeans работает аналогично классу KMeans, но с одним существенным отличием: это параметр размера пакета batch_size. Параметр batch_size управляет количеством случайно отбираемых наблюдеий в каждом пакете. Чем больше размер пакета, тем более дорогостоящим является тренировочный процесс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация методом сдвига к среднему"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется сгруппировать наблюдения без учета количества кластеров или их формы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать кластеризацию методом сдвига к среднему MeanShift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стандартизировать признаки\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект кластеризации методом сдвига к среднему\n",
    "cluster = MeanShift(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = cluster.fit(features_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать новое наблюдение\n",
    "new_observation = [[0.8, 0.8, 0.8, 0.8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать кластер наблюдения\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50161528, -0.32287436,  0.65393539,  0.65261739],\n",
       "       [-1.05954571,  0.75811468, -1.2998088 , -1.25401594]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#взглянуть на центры кластеров\n",
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из недостатков кластеризации методом k -средних, который мы обсуждали выше, заключается в том, что нам нужно устанавливать количество кластеров к априорно до начала тренировки, и что этот метод делает допущения о форме кластеров. Одним из кластеризующих алгоритмов, в котором эти ограничения отсутствуют, называется сдвином к среднему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В алгоритме сдвига к среднему заключена простая идея, которую, правда, несколько трудно объяснить. Поэтому наилучшим подходом может быть аналогия. Представьте себе очень туманное футбольное поле( т е двумерное пространство), на котором находится 100 человек( т е наши наблюдения). Из-за тумана человек может видеть только на небольшое расстояние. Каждую минуту каждый человек оглядывается и делает шаг в сторону большинства людей, которых он видит. С течением времени люди начинают собираться, поскольку они неоднократно предпринимают шаги в сторону все более крупных скоплений людей.  В конечном счете получаются кластеры людей  в пределах поля. Люди назначаются кластерам, в котором они оказываются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фактическая реализация алгоритма сдвига к среднему в scikit-learn (класс MeanShift) сложнее, но следует той же основной логике. Класс MeanShift имее два важных параметра, о которых мы должны знать.\n",
    "\n",
    "1)Ширина полосы bandwidth задает радиус области ( т е ядро), который используется наблюдением для определения направления сдвига. По нашей аналогии ширина полосы, будет тем, как далеко человек может видеть сквозь туман.  Мы можем задать этот параметр вручную, но по умолчанию разумная ширина полосы вычисляется  автоматически(при значительном увеличении вычислительных затрат). \n",
    "\n",
    "2)Иногда в алгоритме сдвига к среднему внутри ядра наблюдения нет других наблюдений. T е человек на нашем футбольном поле  не может видеть ни одного живого человека. По умолчанию класс MeanShift присваивает все эти \"сиротские\" наблюдения ядру ближайшего наблюдения. Однако если требуется исключить этих сирот, то можно установить параметр cluster_all=False, при котором сиротским наблюдениям присваивается метка -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация методом DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется сгруппировать наблюдения в кластеры высокой плотности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать кластеризацию методом DBSCAN (Density-Based Spatial Clustering of Applications with Noise) - плотностный алгоритм пространственной кластеризации в присутствии шума."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стандартизировать признаки\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект плотностной кластеризации DBSCAN\n",
    "cluster = DBSCAN(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#натренировать модель\n",
    "model = cluster.fit(features_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм DBSCAN руководствуется идеей о том, что кластеры будут областями, где много наблюдений плотно упакованы вместе, и не делает никаких допущений о форме кластера. В частности в алгоритме DBSCAN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Выбирается случайное наблюдение x_i\n",
    "\n",
    "2.Если x_i имеет минимальное число близких соседей, то мы рассматриваем его как часть кластера\n",
    "\n",
    "3.Шаг 2 повторяется рекурсивно для всех соседей x_i, затем для соседа соседа итд. Это основные наблюдения кластера.\n",
    "\n",
    "4.После завершения шага 3 выбирается новая случайная точка ( т е перезапуск шага 1)\n",
    "\n",
    "Когда все это будет завершено, мы получим набор ключевых наблюдений для ряда кластеров. Наконец, любое наблюдение, близкое к кластеру, но не являющееся ключевым образцом, считается частью кластера, в то время как любое наблюдение , не близкое к кластеру, помечается как выброс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN имеет 3 основных устанавливаемых параметра:\n",
    "\n",
    "1)eps - максимальное расстояние от наблюдения, чтобы считать другое наблюдение его соседом.\n",
    "\n",
    "2)min_samples - минимальное число наблюдейний, находящихся на расстоянии менее eps от наблюдения, для того, чтобы его можно было считать ключевым наблюдением.\n",
    "\n",
    "3)metric - метрический показатель расстояния, используемый параметром eps, например minkowski или euclidean (обратите внимание, что если используется расстояние Минковского, то может быть использован параметр р для установки мощности метрического показателя Минковского).\n",
    "\n",
    "Если мы посмотрим на кластеры в наших тренировочных данных, то увидим, что были идентифицированы 2 кластера, 0  и 1, в то время, как наблюдения выбросы помечены -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,\n",
       "        0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        1,  1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,\n",
       "        1,  1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
       "       -1,  1,  1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1,\n",
       "       -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#показать принадлежность к кластерам\n",
    "model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация методом иерархического слияния"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется сгрупировать наблюдения, используя иерархию кластеров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать агломеративную кластеризацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стандартизировать признаки\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект агломеративной кластеризации\n",
    "cluster = AgglomerativeClustering(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#натренировать модель\n",
    "model = cluster.fit(features_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Агломеративная кластеризация - это мощный и гибкий алгоритм, который выполняет кластеризацию иерархически. В агломеративной кластеризации все наблюдения начинаются как одноэлементные кластеры. Далее кластеры, удовлетворяющие некоторым критериям , объединяются. Этот процесс повторяется, выращивая кластеры до тех пор, пока не будет достигнута некоторая конечная точка. В библиотеке scikit-learn  в классе AgglomerativeClustering используется параметр связи linkage для определения стратегии слияния, которая своит к минимуму следующее:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-дисперсию объединенных классов по методу Уорда(ward)\n",
    "\n",
    "-среднее расстояние между наблюдениями от пар кластеров по  методу средней связи (average)\n",
    "\n",
    "-максимальное расстояние между наблюдениями от пар кластеров по методу полной связи (complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два других параметра полезно знать  тоже.\n",
    "\n",
    "-параметр близости affinity определяет метрический показатель расстояния, используемый для параметра linkage(minkowski, euclidean)\n",
    "\n",
    "-n_clusters - задает количество кластеров, которые кластеризующий алгоритм будет пытаться найти. \n",
    "Т е кластеры  последовательно объединяются до тех пор, пока количество оставшихся кластеров не будет равняться n_clusters.\n",
    "\n",
    "Как и с дугими кластеризующими алгоритмами, которые мы рассмтрели выше, мы можем использовать атрибут labels_ , чтобы увидеть кластер, которому назначено каждое наблюдение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#показать принадлежность к кластерам\n",
    "model.labels_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
