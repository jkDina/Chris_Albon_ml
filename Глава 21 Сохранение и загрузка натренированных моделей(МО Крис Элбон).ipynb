{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глава 21 Сохранение и загрузка натренированных моделей(МО Крис Элбон)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно интегрировать нашу модель с существующим программным приложением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы должны уметь сохранять наши модели после тренировки и загружать их, когда они необходимы в приложении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение и загрузка модели scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана натренированная модель scikit-learn, и требуется ее сохранить  и загрузить в другом месте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранить модель в качестве файла консервации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#загрузить библиотеки\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать объект классификатор случайных лесов\n",
    "classifer = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#натренировать модель\n",
    "model = classifer.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#сохранить модель с помощью файла консервации\n",
    "joblib.dump(model, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как модель будет сохранена, мы можем использовать библиотеку scikit-learn в нашем конечном приложении (например, в веб-приложении), чтобы загрузить модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить модель из файла\n",
    "classifer = joblib.load(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И использовать ее для выполнения предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создать новое наблюдение\n",
    "new_observation = [[5.2, 3.2, 1.1, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предсказать класс наблюдения\n",
    "classifer.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым шагом при использовании модели в производственной среде является сохранение этой модели  в виде файла, который может быть загружен другим приложением или рабочим процессом.\n",
    "\n",
    "Мы можем сделать это, сохранив модель в виде файла pickle, специфического для Python формата встроенной одноименной библиотеки для консервации данных.\n",
    "\n",
    "В частности, для сохранения модели мы используем библиотеку joblib, которая расширяет библиотеку pickle для случаев, когда имеются большие массивы NumPy  - распространенное явление для моделей, натренированных в библиотеке scikit-learn.\n",
    "\n",
    "При сохранении моделей scikit-learn имейте ввиду, что сохраненные модели могут быть несовместимы между версиями scikit-learn, поэтому может быть полезно включить используемую в модели версию библиотеки scikit-learn в имя файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортировать библиотеку\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получить версию библиотеки skikit-learn\n",
    "scikit_version = sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_0.21.3.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#сохранить модель в качестве файла консервации\n",
    "joblib.dump(model, \"model_{version}.pkl\".format(version=scikit_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение и загрузка модели Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана натренированная модель Keras, и требуется ее сохранить и загрузить в другом месте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранить модель в файле формата HDF5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить библиотеки\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import  layers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#задать начальное значение для генератора псевдослучайных чисел\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#задать желаемое количество признаков\n",
    "number_of_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить данные и вектор из набора данных IMDB о кинофильмах\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(num_words=number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#конвертировать данные IMBD о кинофильмах \n",
    "#в матрицу признаков в кодировке с одним активным состоянием\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализировать нейронную сеть\n",
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#добавить полносвязный слой с активационной функцией ReLU\n",
    "network.add(layers.Dense(\n",
    "    units=16,\n",
    "    activation=\"relu\",\n",
    "    input_shape=(number_of_features,)\n",
    ")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#добавить полносвязный слой с сигмоидальной активационной функцией\n",
    "network.add(layers.Dense(\n",
    "    units=1,\n",
    "    activation=\"sigmoid\"\n",
    ")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#скомпилировать нейронную сеть\n",
    "network.compile(\n",
    "    loss=\"binary_crossentropy\", #перекрестная энтропия\n",
    "    optimizer=\"rmsprop\", #распространение среднеквадратичной ошибки\n",
    "    metrics=[\"accuracy\"] #точностный показатель результтивности\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#натренировать нейронную сеть\n",
    "history = network.fit(\n",
    "    features_train, #признаки\n",
    "    target_train,  #вектор целей\n",
    "    epochs=3,  #количество эпох\n",
    "    verbose=0, #печатать описание после каждой эпохи\n",
    "    batch_size=100,  #количество наблюдений на пакет\n",
    "    validation_data=(features_test, target_test) #тестовые данные\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохранить нейронную сеть\n",
    "network.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы можем загрузить модель в другом приложении либо для дополнительной тренировки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузить нейронную сеть\n",
    "network = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от библиотеки scikit-learn, в библиотеке Keras не рекомендуется сохранять модели с помощью встроенной библиотеке pickle. Вместо этого модели сохраняются как файл HDF5. \n",
    "\n",
    "Файл HDF5 содержит все необходимое  для того, чтобы не только загрузить модель для выполнения предсказаний (те архитектуру и натренированные параметры), но и перезапустить процесс тренировки (те настройки потери и оптимизатора и текущее состояние)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
